{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys \n",
    "import cv2\n",
    "\n",
    "#creamos al clasificador\n",
    "clasificador_rostro = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Detección de esquinas para algoritmo Shi-tomasi\n",
    "detector_esquina_params = dict( maxCorners = 200,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 10,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parametros para lucas Kanade (optical flow)\n",
    "opticalFlow_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 4, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# color aleatorio\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "################################################################################################\n",
    "# Capturar una primer imagen (Mirar defrente a la webcam para una buena captura)\n",
    "ret, frame_previo = cap.read()\n",
    "# muestra la captura\n",
    "cv2.imshow('frame_previo', frame_previo)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "################################################################################################\n",
    "# Aqui detectamos al rostro usando el clasificador creado al inicio, de localizarlo lo cargamos en rostro_detectado\n",
    "\n",
    "gris_frame_previo = cv2.cvtColor(frame_previo, cv2.COLOR_BGR2GRAY)\n",
    "face = clasificador_rostro.detectMultiScale(gris_frame_previo, 1.2, 4)\n",
    "\n",
    "if len(face) == 0:\n",
    "    print (\"No se detecto bien la cara, ponerla más defrente a la cámara\")\n",
    "    quit()\n",
    "\n",
    "for (x,y,w,h) in face:\n",
    "    rostro_detectado = frame_previo[y: y+h, x: x+w]\n",
    "\n",
    "cv2.imshow('cara detectada', rostro_detectado )\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# Aqui detectamos las esquinas del rostro previamente detectado\n",
    "# Dibujares circulos en la esquinas detectadas\n",
    "\n",
    "rostro_detectado_gris = cv2.cvtColor(rostro_detectado,cv2.COLOR_BGR2GRAY)\n",
    "esquinas_t = cv2.goodFeaturesToTrack(rostro_detectado_gris, mask = None, **detector_esquina_params)\n",
    "esquinas = np.int0(esquinas_t)\n",
    "esquinas_para_seguimiento = np.zeros(shape=(len(esquinas),1, 2) , dtype=np.float32 )\n",
    "\n",
    "j=0\n",
    "for i in esquinas:\n",
    "    ix,iy = i.ravel()\n",
    "    cv2.circle(rostro_detectado,(ix,iy),3,255,-1)\n",
    "    cv2.circle(frame_previo,(x+ix,y+iy),3,255,-1)\n",
    "    esquinas_para_seguimiento[j] = [[x+ix, y+iy]]\n",
    "    j+=1    \n",
    "\n",
    "cv2.imshow(\"viejo\", frame_previo)\n",
    "cv2.imshow(\"enfocado\", rostro_detectado)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#. Sobre las esquinas detectadas, realizamos el optical flow y dibujamos los puntos seguidos\n",
    "\n",
    "p0 = esquinas_para_seguimiento\n",
    "\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Calculamos optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(gris_frame_previo, frame_gris, p0 , None, **opticalFlow_params)\n",
    "\n",
    "    #Seleccionamos los mejores puntos\n",
    "    mejores_nuevo_frame = p1[st==1]\n",
    "    mejores_viejo_frame = p0[st==1]\n",
    "\n",
    "    # Dibujar circulos\n",
    "    for i,(nuevo,viejo) in enumerate(zip(mejores_nuevo_frame,mejores_viejo_frame)):\n",
    "        a,b = nuevo.ravel()\n",
    "        c,d = viejo.ravel()\n",
    "        cv2.circle(frame,(a, b),5,color[i].tolist(),-1)\n",
    "        if i == 99:\n",
    "            break\n",
    "\n",
    "            \n",
    "    cv2.imshow('frame', frame)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Actualizando frame previo y puntos de las esquivas previos\n",
    "    gris_frame_previo = frame_gris.copy()\n",
    "    p0 = mejores_nuevo_frame.reshape(-1,1,2)\n",
    "################################################################################################\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rostro detectado\n",
      "Mi porcentaje:  59.0\n",
      "Voy volver a medir\n",
      "---------\n",
      "Rostro detectado\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math  \n",
    "import sys \n",
    "import cv2\n",
    "import time\n",
    "    \n",
    "#creamos al clasificador\n",
    "clasificador_rostro = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detección de esquinas para algoritmo Shi-tomasi\n",
    "detector_esquina_params = dict( maxCorners = 200,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 10,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parametros para lucas Kanade (optical flow)\n",
    "opticalFlow_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 4, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# color aleatorio\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "def mide_esparcimiento(p0, p1, porcent):\n",
    "    cont=0\n",
    "    for p in p0:\n",
    "        dist = math.sqrt( (p1[0][0][0]- p[0][0])**2 + (p1[0][0][1]- p[0][1])**2)\n",
    "        if(dist>100):\n",
    "            cont=cont+1\n",
    "            \n",
    "    #res = np.subtract(p0, p1)\n",
    "    total = p0.shape[0]\n",
    "    pcnt = cont * 100 / total\n",
    "    if(pcnt > porcent):\n",
    "        print(\"Mi porcentaje: \",pcnt)\n",
    "        print(\"Voy volver a medir\");\n",
    "        print(\"---------\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "##########################    \n",
    "#############Aqui empieza\n",
    "###########################\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mide = False\n",
    "continuar =False\n",
    "mi_porcent = 50\n",
    "while(1):\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if(continuar):\n",
    "        #print(\"Voy a continuar con el Optical\")\n",
    "        frame_gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Calculamos optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(gris_frame_previo, frame_gris, p0 , None, **opticalFlow_params)\n",
    "        #Seleccionamos los mejores puntos\n",
    "        mejores_nuevo_frame = p1[st==1]\n",
    "        mejores_viejo_frame = p0[st==1]\n",
    "\n",
    "        # Dibujar circulos\n",
    "        for i,(nuevo,viejo) in enumerate(zip(mejores_nuevo_frame,mejores_viejo_frame)):\n",
    "            a,b = nuevo.ravel()\n",
    "            c,d = viejo.ravel()\n",
    "            cv2.circle(frame,(a, b),5,color[i].tolist(),-1)\n",
    "            if i == 99:\n",
    "                break\n",
    "                \n",
    "        # Mido el espacimiento de los puntos con Euclidiana        \n",
    "        mide = mide_esparcimiento(p0,p1,mi_porcent)\n",
    "        if(mide ==True):\n",
    "            continuar = False\n",
    "\n",
    "        # Actualizando frame previo y puntos de las esquivas previos\n",
    "        gris_frame_previo = frame_gris.copy()\n",
    "        p0 = mejores_nuevo_frame.reshape(-1,1,2)\n",
    "        \n",
    "    else:\n",
    "        frame_previo = frame\n",
    "        gris_frame_previo = cv2.cvtColor(frame_previo, cv2.COLOR_BGR2GRAY)\n",
    "        face = clasificador_rostro.detectMultiScale(gris_frame_previo, 1.2, 4)\n",
    "\n",
    "        if len(face) == 0:\n",
    "            print (\"No se detecto bien la cara, ponerla más defrente a la cámara\")\n",
    "            #quit()\n",
    "        else:\n",
    "            print(\"Rostro detectado\")\n",
    "            continuar = True\n",
    "            for (x,y,w,h) in face:\n",
    "                rostro_detectado = frame_previo[y: y+h, x: x+w]\n",
    "                \n",
    "            #dibujamos los puntos    \n",
    "            rostro_detectado_gris = cv2.cvtColor(rostro_detectado,cv2.COLOR_BGR2GRAY)\n",
    "            esquinas_t = cv2.goodFeaturesToTrack(rostro_detectado_gris, mask = None, **detector_esquina_params)\n",
    "            esquinas = np.int0(esquinas_t)\n",
    "            esquinas_para_seguimiento = np.zeros(shape=(len(esquinas),1, 2) , dtype=np.float32 )\n",
    "            j=0\n",
    "            for i in esquinas:\n",
    "                ix,iy = i.ravel()\n",
    "                cv2.circle(rostro_detectado,(ix,iy),3,255,-1)\n",
    "                cv2.circle(frame_previo,(x+ix,y+iy),3,255,-1)\n",
    "                esquinas_para_seguimiento[j] = [[x+ix, y+iy]]\n",
    "                j+=1\n",
    "            p0 = esquinas_para_seguimiento\n",
    "            \n",
    "    cv2.imshow('frame', frame)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "################################################################################################\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
