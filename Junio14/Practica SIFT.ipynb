{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lapiz.jpg\", cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "img2 = cv2.imread(\"lapizentero.jpg\", cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "\n",
    "\n",
    "# Caracteristicas\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "kp_img2, desc_img2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Correspondencias\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "#FLANN:  \"Fast Library for Approximate Nearest Neighbors\"\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params) # inicializa la funcion que buscará correspondencias\n",
    "matches = flann.knnMatch(desc_image, desc_img2, k=2)   # se le pasea los dos descriptores y un k que significa numero maximo de correspondencias a buscar\n",
    "#Matches es una lista con las mejores correspondencias\n",
    "good_points = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9*n.distance:\n",
    "        good_points.append(m)\n",
    "\n",
    "salida = cv2.drawMatches(img, kp_image, img2, kp_img2, good_points, img2) #imagen1, keypointsIm1, imagen2, keypointsIm2, Correspondencias, ImagenSalida \n",
    "\n",
    "cv2.imshow(\"Salida\", salida)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tomo foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "leido, frame = cap.read()\n",
    "\n",
    "cv2.imwrite(\"vane4.png\", frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"vane.png\", cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "img2 = cv2.imread(\"vane2.png\", cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "# Caracteristicas\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "kp_img2, desc_img2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Correspondencias\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "#FLANN:  \"Fast Library for Approximate Nearest Neighbors\"\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params) # inicializa la funcion que buscará correspondencias\n",
    "matches = flann.knnMatch(desc_image, desc_img2, k=2)   # se le pasea los dos descriptores y un k que significa numero maximo de correspondencias a buscar\n",
    "#Matches es una lista con las mejores correspondencias\n",
    "good_points = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.9*n.distance:\n",
    "        good_points.append(m)\n",
    "\n",
    "salida = cv2.drawMatches(img, kp_image, img2, kp_img2, good_points, img2) #imagen1, keypointsIm1, imagen2, keypointsIm2, Correspondencias, ImagenSalida \n",
    "\n",
    "cv2.imshow(\"Salida\", salida)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"vane4.png\", cv2.IMREAD_GRAYSCALE) \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "       continue    \n",
    "    \n",
    "    img2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #img2 = frame#cv2.imread(frame, cv2.IMREAD_GRAYSCALE) \n",
    "    #    cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Caracteristicas\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "    kp_img2, desc_img2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Correspondencias\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "    #FLANN:  \"Fast Library for Approximate Nearest Neighbors\"\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params) # inicializa la funcion que buscará correspondencias\n",
    "    matches = flann.knnMatch(desc_image, desc_img2, k=2)   # se le pasea los dos descriptores y un k que significa numero maximo de correspondencias a buscar\n",
    "    #Matches es una lista con las mejores correspondencias\n",
    "    good_points = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good_points.append(m)\n",
    "\n",
    "    salida = cv2.drawMatches(img, kp_image, img2, kp_img2, good_points, img2) #imagen1, keypointsIm1, imagen2, keypointsIm2, Correspondencias, ImagenSalida \n",
    "\n",
    "    cv2.imshow(\"Salida\", salida)\n",
    "    \n",
    "    #cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
